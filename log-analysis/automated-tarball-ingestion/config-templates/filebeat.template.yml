###################### Filebeat Configuration Example #########################

#=========================== Filebeat inputs =============================

filebeat.inputs:
  - type: log
    tags: ["system","messages"]
    enabled: true
    paths:
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname/system/*.test
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname/system/*
  - type: log
    tags: ["cassandra","main"]
    enabled: true
    paths:
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname1/cassandra/system.log*
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname2/cassandra/system.log*
    exclude_files: ['\.zip$']  
    multiline.pattern: ^TRACE|DEBUG|WARN|INFO|ERROR
    multiline.negate: true
    multiline.match: after
  - type: log
    tags: ["cassandra","java","gc"]
    enabled: true
    paths:
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname1/cassandra/gc.log*
      #- /home/anant/Projects/Client/ClientName/incident-2020060919/Hostname2/cassandra/gc.log*
    exclude_files: ['\.zip$']
    multiline.pattern: ^TRACE|DEBUG|WARN|INFO|ERROR
    multiline.negate: true
    multiline.match: after

#==================== Elasticsearch template setting ==========================
setup.template.settings:
  index.number_of_shards: 1
  #index.codec: best_compression
  _source.enabled: false
#================================ General =====================================
#name:
#tags: ["service-X", "web-tier"]
#fields:
#  env: staging

#============================== Dashboards =====================================
setup.dashboards.enabled: false

#============================== Kibana =====================================
setup.kibana:
  host: "http://localhost:5601"
#================================ Outputs =====================================
#-------------------------- Elasticsearch output ------------------------------
#output.elasticsearch:
  # Array of hosts to connect to.
  # Currently outputting to logstash instead
  #hosts: ["localhost:9200"]

  # Protocol - either `http` (default) or `https`.
  #protocol: "https"

  # Authentication credentials - either API key or username/password.
  #api_key: "id:api_key"
  #username: "elastic"
  #password: "changeme"

# to debug comment out output.logstash and uncomment this. We're using logstash not Elasticsearch for ingestion
# output.console.pretty: true

#----------------------------- Logstash output --------------------------------
output.logstash:
  enabled: true
  # The Logstash hosts
  hosts: ["localhost:5044"]
  timeout: 15

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"

#================================ Processors =====================================
# Configure processors to enhance or manipulate events generated by the beat.

processors:
  # ( since we are not using a live host.. these are irrelevant) 
  #- add_host_metadata: ~ 
  #- add_cloud_metadata: ~
  #- add_docker_metadata: ~ 
  #- add_kubernetes_metadata: 
  
#------------------------------------- system messages 
  - dissect:
      tokenizer: "%{timestamp} %{+timestamp->} %{+timestamp} %{+timestamp} %{system-host-name} %{component}: %{message}"
      field: "message"
      target_prefix: "ingest"

  - dissect:
      # <path_for_client> will be replaced by the python script
      tokenizer: "<path_for_client>/incident-%{incident-id}/%{host-name}/system/"
      field: "log.file.path"
      target_prefix: "ingest"

#-#------------------------------------ cassandra   
  - dissect:
      tokenizer: "%{loglevel} [%{component}] %{timestamp} %{+timestamp},%{} %{class}.%{}:%{} - %{message}"
      field: "message"
      target_prefix: "ingest"
  #- dissect:
  #    tokenizer: "%{componentname}:%{}"
  #    field: "ingest.component"
  #    target_prefix: "ingest"
  #- dissect:
  #    tokenizer: "%{streamdirection}/%{streamvector}"
  #    field: "ingest.component"
  #    target_prefix: "ingest"
  - dissect:
      # <path_for_client> will be replaced by the python script
      tokenizer: "<path_for_client>/incident-%{incident-id}/%{host-name}/cassandra/"
      field: "log.file.path"
      target_prefix: "ingest"
  - timestamp:
      field: "ingest.timestamp"
      layouts:
        - '2006 Jan _2 15:04:05'
        - '2006-01-02 15:04:05'
      test:
        - '2020 Jun  8 02:40:01'
        - '2001 Jan 17 15:04:01'
        - '2019-06-22 16:33:51'
        - '2020-06-13 12:57:30'
      ignore_failure: true
      target_field: "@timestamp"
  - include_fields:
      fields: [ "ingest", "message","log","input" ]



